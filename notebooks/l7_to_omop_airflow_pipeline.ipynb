{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f690591",
   "metadata": {},
   "source": [
    "# ðŸ“Š Data Ingestion Pipeline: L7 to OMOP CDM via Airflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd875e87",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ” What is Apache Airflow?\n",
    "\n",
    "Apache Airflow is an open-source platform to programmatically author, schedule, and monitor workflows. Think of it as a workflow orchestrator for your data pipelines.\n",
    "\n",
    "### Benefits:\n",
    "- **Modular**: Each task is defined in Python.\n",
    "- **Scalable**: Handles complex workflows with retries and dependencies.\n",
    "- **Visual**: Provides a UI to track job execution and dependencies.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58e1aa2",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ—ï¸ Use Case: Ingesting Clinical Data from L7 (Postgres)\n",
    "\n",
    "The objective is to extract patient data from the L7 Postgres database, apply lightweight transformation to conform with OMOP CDM, and load it into the OMOP-compliant database.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da905d93",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ§  How the DAG Works\n",
    "\n",
    "- **Start** âž¡ï¸ **Extract from L7** âž¡ï¸ **Transform Data** âž¡ï¸ **Load to OMOP DB** âž¡ï¸ **End**\n",
    "\n",
    "Each task in Airflow corresponds to a Python function. The DAG ensures they run in the correct order.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e439eca",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ§¾ Airflow DAG Code Example\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41b356e",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ› ï¸ Requirements\n",
    "\n",
    "- Airflow (`pip install apache-airflow`)\n",
    "- PostgreSQL Driver: `psycopg2`, `sqlalchemy`\n",
    "- Airflow running with DAG folder configured (`~/airflow/dags/`)\n",
    "\n",
    "## ðŸ“š Resources\n",
    "\n",
    "- [Airflow Docs](https://airflow.apache.org/docs/apache-airflow/stable/)\n",
    "- [OMOP CDM Info](https://ohdsi.github.io/CommonDataModel/)\n",
    "- [Astronomer Academy](https://www.astronomer.io/learn/)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6690bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from airflow.utils.dates import days_ago\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'harbinger',\n",
    "    'start_date': days_ago(1),\n",
    "    'retries': 1\n",
    "}\n",
    "\n",
    "dag = DAG(\n",
    "    'l7_to_omop_ingestion',\n",
    "    default_args=default_args,\n",
    "    schedule_interval='@daily',\n",
    "    catchup=False,\n",
    "    description='Ingest L7 clinical data from Postgres to OMOP CDM staging area'\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8e67af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_data_from_l7():\n",
    "    conn = psycopg2.connect(\n",
    "        host='your-l7-host',\n",
    "        dbname='l7_database',\n",
    "        user='your_user',\n",
    "        password='your_password',\n",
    "        port=5432\n",
    "    )\n",
    "    df = pd.read_sql(\"SELECT * FROM patient_table\", conn)\n",
    "    df.to_csv('/tmp/l7_patient_data.csv', index=False)\n",
    "    conn.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d4723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform_data():\n",
    "    df = pd.read_csv('/tmp/l7_patient_data.csv')\n",
    "    df.columns = [col.lower() for col in df.columns]  # sample transformation\n",
    "    df.to_csv('/tmp/transformed_patient_data.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f351980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_to_omop():\n",
    "    engine = sqlalchemy.create_engine('postgresql://omop_user:password@omop-host:5432/omop_db')\n",
    "    df = pd.read_csv('/tmp/transformed_patient_data.csv')\n",
    "    df.to_sql('person', engine, if_exists='append', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce17dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "extract_task = PythonOperator(\n",
    "    task_id='extract_l7',\n",
    "    python_callable=extract_data_from_l7,\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "transform_task = PythonOperator(\n",
    "    task_id='transform_l7',\n",
    "    python_callable=transform_data,\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "load_task = PythonOperator(\n",
    "    task_id='load_omop',\n",
    "    python_callable=load_to_omop,\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "extract_task >> transform_task >> load_task\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
